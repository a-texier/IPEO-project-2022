{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17c64ef2",
   "metadata": {},
   "source": [
    "## import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6346fad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!pip install torch torchvision torchtext pytorch_lightning tensorboard matplotlib tqdm wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7378ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b61cc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as T\n",
    "import numpy as np \n",
    "import csv\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "from torch import nn\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f3b781",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b678862e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import os\n",
    "import zipfile\n",
    "if not os.path.exists(os.getcwd()+\"/ipeo_data\"):\n",
    "    with zipfile.ZipFile(os.getcwd()+\"/ipeo_data.zip\", 'r') as zip_ref:\n",
    "        zip_ref.extractall()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e394c13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = open(os.getcwd()+\"/ipeo_data/splits/train.csv\")\n",
    "train_csv  = csv.reader(train_csv)\n",
    "test_csv = open(os.getcwd()+\"/ipeo_data/splits/test.csv\")\n",
    "test_csv  = csv.reader(test_csv)\n",
    "val_csv = open(os.getcwd()+\"/ipeo_data/splits/val.csv\")\n",
    "val_csv  = csv.reader(val_csv)\n",
    "### CAREFUL need to remove the \"25595_11025_label\" from the validation dataset. Empty image ?\n",
    "### remove direcly in the val excel fil (row = 629)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbaa75dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(train_csv))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3872783",
   "metadata": {},
   "source": [
    "## Set up the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf4a2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "\"\"\"CLASS rocks (1), scree (2), sparse rocks (3), water (4), glacier and permanent snow (5), forest(6), sparse forest(7),\n",
    "grasslands and others (8).\"\"\"\n",
    "\n",
    "class Alpine(Dataset):\n",
    "\n",
    "    # mapping between label class names and indices\n",
    "    LABEL_CLASSES = {\n",
    "      'rocks': \t\t  7,\n",
    "      'scree': \t\t\t    6,\n",
    "      'sparse_rocks': \t  5,\n",
    "      'water': \t\t\t\t      3,\n",
    "      'glacier_and_permanent_snow': \t\t\t    4,\n",
    "      'forest': \t\t\t    1,\n",
    "      'sparse_forest':   2,\n",
    "      'grasslands_and_others': \t\t\t\t    0,\n",
    "      \n",
    "    }\n",
    "\n",
    "    def __init__(self, transforms=None, split='train',frac=1.0):\n",
    "        self.transforms = transforms\n",
    "        #only for label_image\n",
    "        transforms_label = T.Compose([\n",
    "        T.ToTensor()\n",
    "        ])\n",
    "        self.transforms_label = transforms_label\n",
    "        \n",
    "        # prepare data\n",
    "        self.data = []                                  # list of tuples of (image path, label class)\n",
    "        # get images with correct index according to dataset split\n",
    "        if split=='train':\n",
    "            data_csv = open(os.getcwd()+\"/ipeo_data/splits/train.csv\")\n",
    "            data_csv  = list(csv.reader(data_csv))\n",
    "            length = int(frac*len(data_csv))\n",
    "        if split=='test':\n",
    "            data_csv = open(os.getcwd()+\"/ipeo_data/splits/test.csv\")\n",
    "            data_csv  = list(csv.reader(data_csv))\n",
    "            length = int(frac*len(data_csv))\n",
    "        if split=='val':\n",
    "            data_csv = open(os.getcwd()+\"/ipeo_data/splits/val.csv\")\n",
    "            data_csv  = list(csv.reader(data_csv))\n",
    "            length = int(frac*len(data_csv))\n",
    "        \n",
    "        i=0\n",
    "        print(length)\n",
    "        for row in data_csv :\n",
    "            if i<length:\n",
    "                img_name = os.getcwd()+\"/ipeo_data/rgb/\"+row[0]+\"_rgb.tif\"\n",
    "                img_label_name = os.getcwd()+\"/ipeo_data/alpine_label/\"+row[0]+\"_label.tif\"   \n",
    "                i+=1\n",
    "        # example format: 'baseFolder/agricultural/agricultural07.tif'\n",
    "                self.data.append((\n",
    "                    img_name,\n",
    "                    img_label_name          # get index for label class\n",
    "                ))\n",
    "\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "    def __getitem__(self, x):\n",
    "        img_name, img_label_name = self.data[x]\n",
    "    \n",
    "        img = Image.open(img_name)\n",
    "        img_label = Image.open(img_label_name)\n",
    "        \n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "            img_label = self.transforms_label(img_label)\n",
    "        return img,img_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4816b2bf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# initialize the dataset (call the constructor __init__)\n",
    "import matplotlib\n",
    "bounds = np.linspace(0, 7, 8)\n",
    "norm = matplotlib.colors.BoundaryNorm(boundaries=bounds, ncolors=256, extend='both')\n",
    "\n",
    "\n",
    "dataset = Alpine(split= \"train\",frac=1.0)\n",
    "print(f\"dataset of length {len(dataset)}\")\n",
    "# plot individual samples\n",
    "from ipywidgets import interact\n",
    "@interact(idx=range(2000))\n",
    "def plot_sample(idx=0):\n",
    "    img, img_label = dataset[idx]\n",
    "\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(img)\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(np.reshape(img_label,(200,200)), norm=norm, cmap='terrain')\n",
    "    plt.colorbar(matplotlib.cm.ScalarMappable(norm=norm, cmap=\"terrain\"),orientation=\"vertical\",shrink=0.6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ca4a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,1):\n",
    "    img, img_label = dataset[i]\n",
    "    water = np.reshape(img_label,(200,200)).flatten()\n",
    "    if len(water[water==1]) !=0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb99a83",
   "metadata": {},
   "source": [
    "## Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a067af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# mean and standard deviation of the dataset \n",
    "mean=torch.tensor([0.4572, 0.5079, 0.4388])\n",
    "std=torch.tensor([0.2366, 0.2141, 0.1992])\n",
    "# normalize image [0-1] (or 0-255) to zero-mean unit standard deviation\n",
    "normalize = T.Normalize(mean, std)\n",
    "# we invert normalization for plotting later\n",
    "std_inv = 1 / (std + 1e-7)\n",
    "unnormalize = T.Normalize(-mean * std_inv, std_inv)\n",
    "\n",
    "transforms_train = T.Compose([\n",
    "  #TODO: add your own transforms here\n",
    "\n",
    "  T.Resize((200, 200)),\n",
    "  T.ToTensor(),\n",
    "  normalize\n",
    "])\n",
    "\"\"\"\n",
    "  T.RandomResizedCrop((200, 200)),\n",
    "  T.RandomGrayscale(),\n",
    "  T.RandomHorizontalFlip(),\n",
    "  T.RandomApply([T.GaussianBlur(kernel_size=7)]),\n",
    "  T.RandomPosterize(bits=8),\n",
    "  T.RandomVerticalFlip(),\n",
    "  T.ColorJitter(),\n",
    "\"\"\"\n",
    "# we do not augment the validation dataset (aside from resizing and tensor casting)\n",
    "transforms_val = T.Compose([\n",
    "  T.Resize((200, 200)),\n",
    "  T.ToTensor(),\n",
    "  normalize\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564dfe59",
   "metadata": {},
   "source": [
    "## Model  Base on AlexNet + https://github.com/milesial/Pytorch-UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee67fd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        # if you have padding issues, see\n",
    "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
    "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e317372c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Full assembly of the parts to form the complete network \"\"\"\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=False):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = DoubleConv(n_channels, 16)\n",
    "        self.down1 = Down(16, 32)\n",
    "        self.down2 = Down(32, 64)\n",
    "        self.down3 = Down(64, 128)\n",
    "        self.down4 = Down(128, 256)\n",
    "        self.down5 = Down(256, 512)       \n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down6 = Down(512, 1024 // factor)\n",
    "        self.up1 = Up(1024, 512 // factor, bilinear)\n",
    "        self.up2 = Up(512, 256 // factor, bilinear)\n",
    "        self.up3 = Up(256, 128 // factor, bilinear)\n",
    "        self.up4 = Up(128, 64, bilinear)\n",
    "        self.up5 = Up(64, 32, bilinear)\n",
    "        self.up6 = Up(32, 16, bilinear)\n",
    "        \n",
    "        self.outc = OutConv(16, n_classes) #initial size ! (MLP here )\n",
    "        ## Note : the last step == fully connected NN (MLP) || could be repplace by a Random forest methods ! (try)\n",
    "\n",
    "    def forward(self, x,RF=False):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x6 = self.down5(x5)\n",
    "        x7 = self.down6(x6)\n",
    "        \n",
    "        x = self.up1(x7, x6)\n",
    "        x = self.up2(x, x5)\n",
    "        x = self.up3(x, x4)\n",
    "        x = self.up4(x, x3)\n",
    "        x = self.up5(x, x2)\n",
    "        x = self.up6(x, x1)\n",
    "        \n",
    "        if not RF :\n",
    "            logits = self.outc(x)\n",
    "            return logits\n",
    "        else :\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157b23ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67d5bac7",
   "metadata": {},
   "source": [
    "## Getloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f49249e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders(split,frac=1.0):\n",
    "    \n",
    "    \n",
    "    data_dataset = Alpine(transforms=transforms_train, split=split,frac=frac)\n",
    "    shuffle = True\n",
    "    if split == \"test\":\n",
    "        shuffle = False\n",
    "    # data loader\n",
    "    data_loader = DataLoader(data_dataset, \n",
    "                              batch_size  = 2, \n",
    "                              shuffle     = shuffle, \n",
    "                              num_workers = 1,\n",
    "                              pin_memory  = False)\n",
    "    return data_dataset, data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df83458",
   "metadata": {},
   "outputs": [],
   "source": [
    " train_loader = get_dataloaders(\"train\")[1]\n",
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa389a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_epoch(model, optimizer, scheduler, criterion, train_loader, epoch, device,RF):\n",
    "    ### SOLUTION\n",
    "    model.train()\n",
    "    loss_history = []\n",
    "    accuracy_history = []\n",
    "    lr_history = []\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        target = target.type(torch.LongTensor) #avoid an error idk why?\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data, RF)\n",
    "        if not RF :\n",
    "            #shape with not RF : CNN + MLP : prediction already done\n",
    "            #print(output.shape) #[batch,class,200,200]\n",
    "            #print(target.shape)#[batch,1,200,200]\n",
    "            #Newsize for criterion\n",
    "            output = output.permute(1,0,2,3).flatten(1).permute(1,0) #[batch*200*200,class]\n",
    "            target = target.flatten() #[batch*200*200]\n",
    "\n",
    "        else :\n",
    "            #shape with  RF : CNN + RF\n",
    "            #print(output.shape) #[batch,features,200,200] .. ici features = 16\n",
    "            #print(target.shape)#[batch,1,200,200]\n",
    "            #RF prediction\n",
    "            output = RF_CNN(output,target,nbr_class=8) #[batch*200*200,class]\n",
    "            target = target.flatten() #[batch*200*200]\n",
    "            print(output)\n",
    "            print(output.shape)\n",
    "            \n",
    "            \n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        predictions = output.argmax(1).cpu().detach().numpy()\n",
    "        ground_truth = target.cpu().detach().numpy()\n",
    "        #correct = pred.eq(target.view_as(pred)).sum().item()\n",
    "        #ccuracy_float = correct / len(output[0])\n",
    "        \n",
    "        accuracy_float = (predictions == ground_truth).mean()\n",
    "        loss_float = loss.item()\n",
    "\n",
    "        loss_history.append(loss_float)\n",
    "        accuracy_history.append(accuracy_float)\n",
    "        lr_history.append(scheduler.get_last_lr()[0])\n",
    "        if batch_idx % (len(train_loader.dataset) // len(data) // 10) == 0:\n",
    "            print(\n",
    "                f\"Train Epoch: {epoch}-{batch_idx:03d} \"\n",
    "                f\"batch_loss={loss_float:0.2e} \"\n",
    "                f\"batch_acc={accuracy_float:0.3f} \"\n",
    "                f\"lr={scheduler.get_last_lr()[0]:0.3e} \"\n",
    "            )\n",
    "\n",
    "    return loss_history, accuracy_history, lr_history\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, device, val_loader, criterion,RF):\n",
    "    model.eval()  # Important: eval mode (affects dropout, batch norm etc)\n",
    "    test_loss = 0\n",
    "    accuracy_float = 0 \n",
    "    for data, target in val_loader:\n",
    "        target = target.type(torch.LongTensor) #avoid an error idk why?\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data,RF=False)\n",
    "        output = model(data, RF)\n",
    "        if not RF :\n",
    "            #shape with not RF : CNN + MLP : prediction already done\n",
    "            #print(output.shape) #[batch,class,200,200]\n",
    "            #print(target.shape)#[batch,1,200,200]\n",
    "            #Newsize for criterion\n",
    "            output = output.permute(1,0,2,3).flatten(1).permute(1,0) #[batch*200*200,class]\n",
    "            target = target.flatten() #[batch*200*200]\n",
    "        else :\n",
    "            #shape with  RF : CNN + RF\n",
    "            #print(output.shape) #[batch,features,200,200] .. ici features = 16\n",
    "            #print(target.shape)#[batch,1,200,200]\n",
    "            #RF prediction\n",
    "            output = RF_CNN(output,target,nbr_class=8) #[batch*200*200,class]\n",
    "            output = output.to(device)\n",
    "            target = target.to(device)\n",
    "            target = target.flatten() #[batch*200*200]\n",
    "        \n",
    "        test_loss += criterion(output, target)\n",
    "        \n",
    "        predictions = output.argmax(1).cpu().detach().numpy()\n",
    "        ground_truth = target.cpu().detach().numpy()\n",
    "        \n",
    "        accuracy_float += (predictions == ground_truth).mean()\n",
    "\n",
    "    test_loss /= len(val_loader)\n",
    "\n",
    "    print(\n",
    "        \"Val set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\".format(\n",
    "            test_loss,\n",
    "            accuracy_float,\n",
    "            len(val_loader),\n",
    "            100.0 * accuracy_float / len(val_loader),\n",
    "        )\n",
    "    )\n",
    "    return test_loss, accuracy_float / len(val_loader)\n",
    "\n",
    "\n",
    "def run_training(\n",
    "    model_factory,\n",
    "    num_epochs,\n",
    "    optimizer_kwargs,\n",
    "    device=\"cuda\",\n",
    "    RF=False,\n",
    "    frac=1.0,\n",
    "):\n",
    "    # ===== Data Loading =====\n",
    "    train_loader = get_dataloaders(\"train\",frac=frac)[1]\n",
    "    val_loader = get_dataloaders(\"val\",frac=frac)[1]\n",
    "\n",
    "    # ===== Model, Optimizer and Criterion =====\n",
    "    model = UNet(3,8)\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), **optimizer_kwargs)\n",
    "    criterion = torch.nn.functional.cross_entropy\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer,\n",
    "        T_max=(len(train_loader.dataset) * num_epochs) // train_loader.batch_size,\n",
    "    )\n",
    "\n",
    "    # ===== Train Model =====\n",
    "    lr_history = []\n",
    "    train_loss_history = []\n",
    "    train_acc_history = []\n",
    "    val_loss_history = []\n",
    "    val_acc_history = []\n",
    "    \n",
    "    print(\"le training commence!\")\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        train_loss, train_acc, lrs = train_epoch(\n",
    "            model, optimizer, scheduler, criterion, train_loader, epoch, device,RF\n",
    "        )\n",
    "        train_loss_history.extend(train_loss)\n",
    "        train_acc_history.extend(train_acc)\n",
    "        lr_history.extend(lrs)\n",
    "\n",
    "        val_loss, val_acc = validate(model, device, val_loader, criterion,RF)\n",
    "        val_loss_history.append(val_loss)\n",
    "        val_acc_history.append(val_acc)\n",
    "    \n",
    "    #test part\n",
    "    \n",
    "    return (sum(train_acc) / len(train_acc), val_acc, model)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6407b0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" IF curve .. (not working)\n",
    "    # ===== Plot training curves =====\n",
    "    n_train = len(train_acc_history)\n",
    "    t_train = num_epochs * np.arange(n_train) / n_train\n",
    "    t_val = np.arange(1, num_epochs + 1)\n",
    "\n",
    "    plt.figure(figsize=(6.4 * 3, 4.8))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(t_train, train_acc_history, label=\"Train\")\n",
    "    plt.plot(t_val, val_acc_history, label=\"Val\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(t_train, train_loss_history, label=\"Train\")\n",
    "    plt.plot(t_val, val_loss_history, label=\"Val\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(t_train, lr_history)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Learning Rate\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18e8c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from RF_from_CNN import RF_CNN\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "image_size = 400\n",
    "model_factory = UNet\n",
    "num_epochs = 1\n",
    "frac=1.0\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "optimizer_kwargs = dict(\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-2,\n",
    ")\n",
    "\n",
    "train_acc,val_acc,model = run_training(\n",
    "    model_factory=UNet,\n",
    "    num_epochs=num_epochs,\n",
    "    optimizer_kwargs=optimizer_kwargs,\n",
    "    device=device,\n",
    "    RF=True,\n",
    "    frac=frac\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea2ea05",
   "metadata": {},
   "source": [
    "## Testing the  model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd8a345",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefa2758",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8715b8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset,test_loader = get_dataloaders(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442e0628",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad() \n",
    "def test(model, device, test_loader, criterion):\n",
    "    test_loss = 0\n",
    "    accuracy_float = 0 \n",
    "    print(len(test_loader))\n",
    "    test_pred = []\n",
    "    test_ground_truth =[]\n",
    "    all_acc = []\n",
    "    for data, target in test_loader:\n",
    "        batch_size = len(data)\n",
    "        target = target.type(torch.LongTensor) #avoid an error idk why?\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        #print(output.shape) #[batch,class,200,200]\n",
    "        #print(target.shape)#[batch,1,200,200]\n",
    "        output = output.permute(1,0,2,3).flatten(1).permute(1,0) #[batch*200*200,class]    \n",
    "        target = target.flatten() #[batch*200*200]\n",
    "   \n",
    "        \n",
    "        test_loss += criterion(output, target)\n",
    "        \n",
    "        predictions = output.argmax(1).cpu().detach().numpy()\n",
    "        ground_truth = target.cpu().detach().numpy()\n",
    "        \n",
    "        predictions = predictions.reshape((batch_size,200,200))\n",
    "        ground_truth = ground_truth.reshape((batch_size,200,200))\n",
    "        \n",
    "        accuracy_batch = (predictions == ground_truth).mean()\n",
    "        accuracy_float += accuracy_batch\n",
    "        for i in range(batch_size):            \n",
    "            all_acc.append((predictions[i] == ground_truth[i]).mean())\n",
    "            test_pred.append(predictions[i])\n",
    "            test_ground_truth.append(ground_truth[i])\n",
    "           \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print(\n",
    "        \"Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\".format(\n",
    "            test_loss,\n",
    "            accuracy_float,\n",
    "            len(test_loader),\n",
    "            100.0 * accuracy_float / len(test_loader),\n",
    "        )\n",
    "    )\n",
    "    return test_loss, accuracy_float / len(test_loader.dataset),test_pred,test_ground_truth,all_acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8ce1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "criterion = torch.nn.functional.cross_entropy\n",
    "test_loss, test_acc,test_pred,test_ground_truth,all_acc = test(model, device, test_loader, criterion) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59954d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print predictions\n",
    "#test_dataset\n",
    "LABEL_CLASSES = {\n",
    "      'rocks': \t\t  7,\n",
    "      'scree': \t\t\t    6,\n",
    "      'sparse_rocks': \t  5,\n",
    "      'water': \t\t\t\t      3,\n",
    "      'glacier_and_permanent_snow': \t\t\t    4,\n",
    "      'forest': \t\t\t    1,\n",
    "      'sparse_forest':   2,\n",
    "      'grasslands_and_others': \t\t\t\t    0,\n",
    "      \n",
    "    }\n",
    "    \n",
    "import matplotlib\n",
    "print(f\"dataset of length {len(test_dataset)}\")\n",
    "# plot individual samples\n",
    "bounds = np.linspace(0, 7, 8)\n",
    "norm = matplotlib.colors.BoundaryNorm(boundaries=bounds, ncolors=256, extend='both')\n",
    "\n",
    "from ipywidgets import interact\n",
    "@interact(idx=range(214))\n",
    "def plot_sample(idx=0):\n",
    "\n",
    "    img_data, img_label = test_dataset[idx][0],test_dataset[idx][1]\n",
    "    img_pred = test_pred[idx]\n",
    "    print(img_label.shape)\n",
    "    \n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.subplot(1,3,1,title=\"Real image\")\n",
    "    fig = plt.imshow(unnormalize(img_data).permute(1,2,0).cpu().detach().numpy())\n",
    "    \n",
    "    plt.subplot(1,3,2,title=\"Predict label \\n accuracy \"+str(all_acc[idx]))\n",
    "    plt.imshow(img_pred, norm=norm, cmap='terrain')\n",
    "    plt.colorbar(matplotlib.cm.ScalarMappable(norm=norm, cmap=\"terrain\"),orientation=\"vertical\",shrink=0.3)\n",
    "    \n",
    "    plt.subplot(1,3,3,title=\"True label\")\n",
    "    plt.imshow(np.reshape(img_label,(200,200)), norm=norm, cmap='terrain')\n",
    "    \n",
    "    plt.colorbar(matplotlib.cm.ScalarMappable(norm=norm, cmap=\"terrain\"),orientation=\"vertical\",shrink=0.3)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9880ffc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data, img_label = test_dataset[5][0],test_dataset[5][1]\n",
    "img_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d78971",
   "metadata": {},
   "source": [
    "# Confusion matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a8dd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(conf_matrix):\n",
    "    fig, ax = plt.subplots(figsize=(9, 9))\n",
    "    ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.5)\n",
    "    for i in range(conf_matrix.shape[0]):\n",
    "        for j in range(conf_matrix.shape[1]):\n",
    "            ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='x-large')\n",
    "    \n",
    "    plt.xlabel('Predictions', fontsize=18)\n",
    "    plt.ylabel('Ground Truth', fontsize=18)\n",
    "    plt.title('Confusion Matrix', fontsize=18)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de53541",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "all_gt_labels = np.array(test_ground_truth).flatten()\n",
    "all_predictions = np.array(test_pred).flatten()\n",
    "conf_matrix = confusion_matrix(all_gt_labels, all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aede65e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c118a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.where(all_gt_labels==2)[0]),len(np.where(all_predictions==3)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae636bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_CLASSES = {\n",
    "      'rocks': \t\t  7,\n",
    "      'scree': \t\t\t    6,\n",
    "      'sparse_rocks': \t  5,\n",
    "      'water': \t\t\t\t      3,\n",
    "      'glacier_and_permanent_snow': \t\t\t    4,\n",
    "      'forest': \t\t\t    1,\n",
    "      'sparse_forest':   2,\n",
    "      'grasslands_and_others': \t\t\t\t    0,\n",
    "      \n",
    "    }\n",
    "    \n",
    "def data_information(conf_matrix):\n",
    "    fig, ax = plt.subplots(figsize=(12, 9))\n",
    "    ax.matshow(np.zeros((6,conf_matrix.shape[1])), cmap=plt.cm.Blues, alpha=1)\n",
    "    for j in range(len(conf_matrix)):\n",
    "        ax.text(x=j, y=0,s=np.round(np.sum(conf_matrix[j,:])/np.sum(conf_matrix),decimals=2), va='center', ha='center', size='x-large')\n",
    "        ax.text(x=j, y=1,s=np.round(conf_matrix[j,j]/np.sum(conf_matrix[j,:]),decimals=2), va='center', ha='center', size='x-large')\n",
    "        ax.text(x=j, y=2,s=np.round(conf_matrix[j,j]/np.sum(conf_matrix[:,j]),decimals=2), va='center', ha='center', size='x-large')\n",
    "        \n",
    "        \n",
    "    ax.text(x=0, y=4,s=np.round(np.sum(np.diag(conf_matrix))/np.sum(conf_matrix),decimals=2), va='center', ha='center', size='x-large')\n",
    "    ax.text(x=0, y=5,s=np.round(np.sum(np.diag(conf_matrix)/np.sum(conf_matrix,axis=1))/len(conf_matrix),decimals=2), va='center', ha='center', size='x-large')\n",
    "    \n",
    "    ax.set_yticklabels(['',\"Pixel_class\", \"Producer_accuracy\",\"User_accuracy\", \"\",\"Overall_accuracy\", \"Average_accuracy\"])\n",
    "    ax.set_xticklabels(['',\"grasslands_and_others\",\"forest\",\"sparse_forest\",\"water\",\"glacier/snow\",\"sparse_rock\",\"scree\",\"rocks\"])\n",
    "\n",
    "\n",
    "    plt.title('data_information', fontsize=18)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e130f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_information(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09d0767",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_acc = np.sum(np.diag(conf_matrix))/np.sum(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853732f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(conf_matrix,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a708cb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b175fd7a",
   "metadata": {},
   "source": [
    "## Number of pixels per class in the entire training set (no need to run)\n",
    "Answer in commentary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e318845",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"No need to rerun!\")\n",
    "raise ValueError('No need to rerun!')\n",
    "\n",
    "img, img_label = dataset[0]\n",
    "img, img_label = np.array(img), np.array(img_label)\n",
    "\n",
    "num_pix_grasslands_and_others = 0\n",
    "num_pix_forest = 0\n",
    "num_pix_sparse_forest = 0\n",
    "num_pix_water = 0\n",
    "num_pix_glacier_and_permanent_snow = 0\n",
    "num_pix_sparse_rocks = 0\n",
    "num_pix_scree = 0\n",
    "num_pix_rocks = 0\n",
    "num_pix_misclassified = 0\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    img, img_label = dataset[i]\n",
    "    img, img_label = np.array(img), np.array(img_label)\n",
    "    img_label = img_label.flatten()\n",
    "    for j in range(img_label.shape[0]):\n",
    "        if img_label[j] == 0:\n",
    "            num_pix_grasslands_and_others += 1\n",
    "        elif img_label[j] == 1 :\n",
    "            num_pix_forest += 1\n",
    "        elif img_label[j] == 2 :\n",
    "            num_pix_sparse_forest += 1\n",
    "        elif img_label[j] == 3 :\n",
    "            num_pix_water += 1\n",
    "        elif img_label[j] == 4 :\n",
    "            num_pix_glacier_and_permanent_snow += 1\n",
    "        elif img_label[j] == 5 :\n",
    "            num_pix_sparse_rocks += 1\n",
    "        elif img_label[j] == 6 :\n",
    "            num_pix_scree += 1\n",
    "        elif img_label[j] == 7 :\n",
    "            num_pix_rocks += 1\n",
    "        else:\n",
    "            num_pix_misclassified += 1\n",
    "            \n",
    "print(f\"Number of pixels of grasslands and others : {num_pix_grasslands_and_others}\")\n",
    "print(f\"Number of pixels of forest : {num_pix_forest}\")\n",
    "print(f\"Number of pixels of sparse forest : {num_pix_sparse_forest}\")\n",
    "print(f\"Number of pixels of water : {num_pix_water}\")\n",
    "print(f\"Number of pixels of glacier and permanent snow : {num_pix_glacier_and_permanent_snow}\")\n",
    "print(f\"Number of pixels of sparse rocks : {num_pix_sparse_rocks}\")\n",
    "print(f\"Number of pixels of scree : {num_pix_scree}\")\n",
    "print(f\"Number of pixels of rocks : {num_pix_rocks}\")\n",
    "print(f\"Number of pixels missclassified : {num_pix_misclassified}\")\n",
    "\n",
    "\"\"\"\n",
    "ANSWER:\n",
    "Number of pixels of grasslands and others : 72519725\n",
    "Number of pixels of forest : 19336033\n",
    "Number of pixels of sparse forest : 18342686\n",
    "Number of pixels of water : 5936946\n",
    "Number of pixels of glacier and permanent snow : 10797402\n",
    "Number of pixels of sparse rocks : 16857098\n",
    "Number of pixels of scree : 78876458\n",
    "Number of pixels of rocks : 71613652\n",
    "Number of pixels missclassified : 0\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c285e9",
   "metadata": {},
   "source": [
    "## Test ( Image input 400 sur 400 / label 200 sur 200 --> need to resize the input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ae0a2d",
   "metadata": {},
   "source": [
    "### Find the mean and stf of the Dataset || No need run  anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cc6ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_train = T.Compose([\n",
    "  T.ToTensor()\n",
    "])\n",
    "\n",
    "# dataset\n",
    "train_dataset = Alpine(transforms=transforms_train, split='train')\n",
    "test_dataset = Alpine(transforms=transforms_train, split='test')\n",
    "val_dataset = Alpine(transforms=transforms_train, split='val')\n",
    "\n",
    "# data loader\n",
    "train_loader = DataLoader(train_dataset, \n",
    "                          batch_size  = 16, \n",
    "                          shuffle     = False, \n",
    "                          num_workers = 1,\n",
    "                          pin_memory  = True)\n",
    "test_loader = DataLoader(test_dataset, \n",
    "                          batch_size  = 16, \n",
    "                          shuffle     = False, \n",
    "                          num_workers = 1,\n",
    "                          pin_memory  = True)\n",
    "val_loader = DataLoader(val_dataset, \n",
    "                          batch_size  = 16, \n",
    "                          shuffle     = False, \n",
    "                          num_workers = 1,\n",
    "                          pin_memory  = True)\n",
    "\n",
    "def mean_std():\n",
    "    ####### COMPUTE MEAN / STD\n",
    "\n",
    "    # placeholders\n",
    "    psum    = torch.tensor([0.0, 0.0, 0.0])\n",
    "    psum_sq = torch.tensor([0.0, 0.0, 0.0])\n",
    "\n",
    "    #The first two steps are done in the snippet below. Note that we set axis = [0, 2, 3] \n",
    "    #to compute mean values with respect to axis 1. The dimensions of inputs is [batch_size x 3 x image_size x image_size],\n",
    "    #so we need to make sure we aggregate values per each RGB channel separately.\n",
    "\n",
    "    # loop through images\n",
    "    for img,img_label in tqdm(train_loader):\n",
    "        psum    += img.sum(axis        = [0, 2, 3])\n",
    "        psum_sq += (img ** 2).sum(axis = [0, 2, 3])\n",
    "\n",
    "    for img,img_label in tqdm(test_loader):\n",
    "        psum    += img.sum(axis        = [0, 2, 3])\n",
    "        psum_sq += (img ** 2).sum(axis = [0, 2, 3])\n",
    "\n",
    "    for img,img_label in tqdm(val_loader):\n",
    "        psum    += img.sum(axis        = [0, 2, 3])\n",
    "        psum_sq += (img ** 2).sum(axis = [0, 2, 3])\n",
    "\n",
    "    ####### FINAL CALCULATIONS\n",
    "\n",
    "    # image count\n",
    "    s = 0\n",
    "    for image in test_csv :\n",
    "        s+=1\n",
    "    for image in train_csv :\n",
    "        s+=1\n",
    "    for image in val_csv :\n",
    "        s+=1\n",
    "    # pixel count\n",
    "    image_size = train_dataset[0][0].shape #[3,400,400]     \n",
    "    count = s * image_size[1] * image_size[1]\n",
    "\n",
    "    # mean and std\n",
    "    total_mean = psum / count\n",
    "    total_var  = (psum_sq / count) - (total_mean ** 2)\n",
    "    total_std  = torch.sqrt(total_var)\n",
    "\n",
    "    # output\n",
    "    print('mean: '  + str(total_mean))\n",
    "    print('std:  '  + str(total_std))\n",
    "    return total_mean,total_std\n",
    "# mean,std = mean_std()\n",
    "\"\"\"\n",
    "GOT: \n",
    "mean: tensor([0.4572, 0.5079, 0.4388])\n",
    "std:  tensor([0.2366, 0.2141, 0.1992])\n",
    "Use in normalisze transforms\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
