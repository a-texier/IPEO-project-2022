{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a44174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following functions are the same you implemented the past week\n",
    "# You do not need to edit the functions of this code block (just run it)\n",
    "def convert_to_shape_pixels_by_bands(data):\n",
    "    num_dimensions = len(data.shape)\n",
    "    assert(num_dimensions == 2 or num_dimensions == 3)\n",
    "    if num_dimensions == 3:\n",
    "        num_bands = data.shape[2]\n",
    "        return data.reshape((-1, num_bands))\n",
    "    else:\n",
    "        return data\n",
    "\n",
    "def compute_average_feature(data):\n",
    "    # If needed convert data to the shape (num_pixels x num_bands)\n",
    "    data_2d = convert_to_shape_pixels_by_bands(data)\n",
    "    # Get the number of bands\n",
    "    num_bands = data_2d.shape[1]\n",
    "    avg_features = np.zeros(num_bands)\n",
    "    for b in range(num_bands):\n",
    "        # Compute the average value of each band (use the function np.mean)\n",
    "        avg_features[b] = np.mean(data_2d[:, b])\n",
    "    return avg_features\n",
    "\n",
    "def compute_standard_deviation_feature(data):\n",
    "    # If needed convert data to the shape (num_pixels x num_bands)\n",
    "    data_2d = convert_to_shape_pixels_by_bands(data)\n",
    "    # Compute the standard deviation feature (using the numpy function np.std)\n",
    "    #       as in the function compute_average_feature iterate over the bands\n",
    "    #       and compute one value for each band\n",
    "    num_bands = data_2d.shape[1]\n",
    "    avg_features = np.zeros(num_bands)\n",
    "    for b in range(num_bands):\n",
    "        avg_features[b] = np.std(data_2d[:, b])\n",
    "    return avg_features\n",
    "\n",
    "def compute_histogram_feature(data, num_bins=10):\n",
    "    # If needed convert data to the shape (num_pixels x num_bands)\n",
    "    data_2d = convert_to_shape_pixels_by_bands(data)\n",
    "    num_bands = data_2d.shape[1]\n",
    "    hist_features = np.zeros((num_bands, num_bins)).astype(np.float32)\n",
    "    for b in range(num_bands):\n",
    "        # Compute the histogram for each band \n",
    "        #       use the function np.histogram(array, bins=num_bins)\n",
    "        hist, boundaries = np.histogram(data_2d[:, b], bins=num_bins)\n",
    "        hist_features[b, :] = hist\n",
    "    # Return a 1D array containing all the values\n",
    "    return hist_features.flatten()\n",
    "\n",
    "def compute_image_features_from_regions(image, segmentation_map):\n",
    "    num_regions = len(np.unique(segmentation_map))\n",
    "    all_features = []\n",
    "    for id_region in range(num_regions):\n",
    "        # Obtain pixel values of each regions, with shape (num_pixels x num_bands)\n",
    "        pixel_values = image[segmentation_map==id_region]\n",
    "        # Compute the average, standard deviation and histogram features\n",
    "        #       and concatenated them unsing the function (np.concatenate)\n",
    "        avg = compute_average_feature(pixel_values)\n",
    "        features = compute_standard_deviation_feature(pixel_values)\n",
    "        hist_features = compute_histogram_feature(pixel_values)\n",
    "        features = np.concatenate([avg, features, hist_features])\n",
    "        # Add concatenated features to the variable all_features\n",
    "        all_features.append(features)\n",
    "    # convert list to numpy array of shape: (num_regions x num_bands)\n",
    "    return np.array(all_features).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d5ee0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_per_region(segmented_image, label_map):\n",
    "    \"\"\"\n",
    "    Returns a 1D numpy array that contains the label for each region, shape: (num_regions)\n",
    "            For each region, we obtain the label that has the largest intersection with it\n",
    "    \"\"\"\n",
    "    num_regions = len(np.unique(segmented_image))\n",
    "    num_labels = len(np.unique(label_map))\n",
    "    region_labels = []\n",
    "    for region_id in range(num_regions):\n",
    "        mask_region = segmented_image == region_id\n",
    "        \n",
    "        intersection_per_label = []\n",
    "        for label_id in range(num_labels):\n",
    "            mask_label = label_map == label_id\n",
    "            # Compute intersection of each region with each label\n",
    "            intersection = np.sum(mask_region * mask_label)\n",
    "            intersection_per_label.append(intersection)\n",
    "        \n",
    "        intersection_per_label = np.array(intersection_per_label)\n",
    "        # Obtain the index of the label with largest intersection\n",
    "        selected_label = np.argmax(intersection_per_label)\n",
    "        region_labels.append(selected_label)\n",
    "    \n",
    "    return np.array(region_labels).astype(np.uint32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb58f793",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage.io import imsave, imread\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "def RF_feature_region(output,target):\n",
    "    # Create arrays of training targets and features \n",
    "    all_train_region_features = []\n",
    "    all_train_region_labels = []\n",
    "\n",
    "    for image in output:\n",
    "        # TODO: read segmented image\n",
    "        segmented_image = slic(image, n_segments=1000, start_label=0)\n",
    "        # TODO: read ground truth image\n",
    "        gt_image = target\n",
    "        # TODO: Get labels per region using the function \"get_label_per_region\" defined above\n",
    "        region_labels = get_label_per_region(segmented_image, gt_image)\n",
    "        # Add current region labels to the variable all_train_region_labels\n",
    "        all_train_region_labels.append(region_labels)\n",
    "        # TODO: compute features \n",
    "        region_features = compute_image_features_from_regions(image, segmented_image)\n",
    "        # Add current region features to the variable all_train_region_features\n",
    "        all_train_region_features.append(region_features)\n",
    "\n",
    "    # Tranforming the list all_train_region_labels in an array of shape: (num_all_regions)\n",
    "    train_labels = np.concatenate(all_train_region_labels)\n",
    "    print(\"train_labels shape \" + str(train_labels.shape))\n",
    "    # Tranforming the list all_train_region_features in an array of shape: (num_all_regions, num_features)\n",
    "    train_features = np.concatenate(all_train_region_features)\n",
    "    print(\"train_features shape \" + str(train_features.shape))\n",
    "    mean_per_feature = np.mean(train_features, axis=0)\n",
    "    std_per_feature = np.std(train_features, axis=0)\n",
    "    # TODO: normalize features by substracting the mean and dividing by the standard deviation\n",
    "    norm_train_features = (train_features - mean_per_feature) / std_per_feature\n",
    "\n",
    "    # TODO: create random forest classifier with the parameter random_state=10\n",
    "    classifier = RandomForestClassifier(random_state=10)\n",
    "    # TODO: fit the model with the normalized features\n",
    "    classifier.fit(norm_train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d4e656",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "916a021a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def RF_CNN(output,target,nbr_class):\n",
    "    # Create arrays of training targets and features \n",
    "    all_train_features = []\n",
    "    all_train_labels = []\n",
    "\n",
    "    for i in range(len(output)):\n",
    "        #print(output.shape) #[batch,features,200,200]\n",
    "        #print(target.shape)#[batch,1,200,200] \n",
    "        label_image = target[i].flatten() #[200*200]\n",
    "        all_train_labels.append(label_image.cpu())\n",
    "        # TODO: compute features \n",
    "        train_features_pixel = output[i].flatten(1).permute(1,0) #[200*200,features]\n",
    "        # Add current region features to the variable all_train_region_features\n",
    "        all_train_features.append(train_features_pixel.cpu())\n",
    "\n",
    "    # Tranforming the list all_train_region_labels in an array of shape: (num_all_regions)\n",
    "    train_labels = torch.cat(all_train_labels)\n",
    "\n",
    "    # Tranforming the list all_train_region_features in an array of shape: (num_all_regions, num_features)\n",
    "    train_features = torch.cat(all_train_features)\n",
    "\n",
    "    mean_per_feature = torch.mean(train_features, axis=0)\n",
    "    std_per_feature = torch.std(train_features, axis=0)\n",
    "    # TODO: normalize features by substracting the mean and dividing by the standard deviation\n",
    "    norm_train_features = (train_features - mean_per_feature) / std_per_feature\n",
    "\n",
    "    # TODO: create random forest classifier with the parameter random_state=10\n",
    "    classifier = RandomForestClassifier(random_state=10, n_estimators=20, max_depth=5)\n",
    "    # TODO: fit the model with the normalized features\n",
    "    classifier.fit(norm_train_features, train_labels)\n",
    "                   \n",
    "    # Predict label of regions \n",
    "    label_predictions = classifier.predict(norm_train_features) #[batch*200*200]\n",
    "    # Compute label predictions per pixel\n",
    "    #desire predicion_map shape  #[batch*200*200,class]\n",
    "    predicion_map = torch.zeros((output.shape[0]*output.shape[2]*output.shape[3],nbr_class)).astype(np.uint8)\n",
    "    for j in range(len(predicion_map)):\n",
    "        predicion_map[j,label_predictions[j]] = label_predictions[j]\n",
    "    \n",
    "    print(\"RF_done\")\n",
    "    print(torch.tensor(predicion_map))\n",
    "    return torch.tensor(predicion_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec992e01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e66935b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([2,3,4,1,2,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ea982d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.zeros((len(a),7))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9f218248",
   "metadata": {},
   "outputs": [],
   "source": [
    "b[0,a[0]]=a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5d013e53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 2., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ea54bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b960bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342d2e57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21b39b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
