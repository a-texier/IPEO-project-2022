{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17c64ef2",
   "metadata": {},
   "source": [
    "## import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6346fad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in ./ipeo_venv/lib/python3.7/site-packages (1.13.0)\n",
      "Requirement already satisfied: torchvision in ./ipeo_venv/lib/python3.7/site-packages (0.14.0)\n",
      "Collecting torchtext\n",
      "  Downloading torchtext-0.14.0-cp37-cp37m-manylinux1_x86_64.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pytorch_lightning\n",
      "  Downloading pytorch_lightning-1.8.2-py3-none-any.whl (798 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.7/798.7 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard\n",
      "  Downloading tensorboard-2.11.0-py3-none-any.whl (6.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in ./ipeo_venv/lib/python3.7/site-packages (3.5.3)\n",
      "Requirement already satisfied: tqdm in ./ipeo_venv/lib/python3.7/site-packages (4.64.1)\n",
      "Requirement already satisfied: wget in ./ipeo_venv/lib/python3.7/site-packages (3.2)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in ./ipeo_venv/lib/python3.7/site-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in ./ipeo_venv/lib/python3.7/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in ./ipeo_venv/lib/python3.7/site-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in ./ipeo_venv/lib/python3.7/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: typing-extensions in ./ipeo_venv/lib/python3.7/site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: wheel in ./ipeo_venv/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.38.4)\n",
      "Requirement already satisfied: setuptools in ./ipeo_venv/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (41.2.0)\n",
      "Requirement already satisfied: requests in ./ipeo_venv/lib/python3.7/site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: numpy in ./ipeo_venv/lib/python3.7/site-packages (from torchvision) (1.21.6)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./ipeo_venv/lib/python3.7/site-packages (from torchvision) (9.3.0)\n",
      "Requirement already satisfied: packaging>=17.0 in ./ipeo_venv/lib/python3.7/site-packages (from pytorch_lightning) (21.3)\n",
      "Collecting torchmetrics>=0.7.0\n",
      "  Downloading torchmetrics-0.10.3-py3-none-any.whl (529 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m529.7/529.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting lightning-utilities==0.3.*\n",
      "  Downloading lightning_utilities-0.3.0-py3-none-any.whl (15 kB)\n",
      "Collecting fsspec[http]>2021.06.0\n",
      "  Downloading fsspec-2022.11.0-py3-none-any.whl (139 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.5/139.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting PyYAML>=5.4\n",
      "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m596.3/596.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting fire\n",
      "  Downloading fire-0.4.0.tar.gz (87 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.7/87.7 kB\u001b[0m \u001b[31m935.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting absl-py>=0.4\n",
      "  Downloading absl_py-1.3.0-py3-none-any.whl (124 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.6/124.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.14.1-py2.py3-none-any.whl (175 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.4/175.4 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting werkzeug>=1.0.1\n",
      "  Downloading Werkzeug-2.2.2-py3-none-any.whl (232 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.7/232.7 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting grpcio>=1.24.3\n",
      "  Downloading grpcio-1.50.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.3/93.3 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting protobuf<4,>=3.9.2\n",
      "  Downloading protobuf-3.20.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in ./ipeo_venv/lib/python3.7/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./ipeo_venv/lib/python3.7/site-packages (from matplotlib) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./ipeo_venv/lib/python3.7/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: cycler>=0.10 in ./ipeo_venv/lib/python3.7/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in ./ipeo_venv/lib/python3.7/site-packages (from matplotlib) (3.0.9)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1\n",
      "  Downloading aiohttp-3.8.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (948 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m948.0/948.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
      "Requirement already satisfied: six>=1.9.0 in ./ipeo_venv/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.16.0)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in ./ipeo_venv/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard) (5.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./ipeo_venv/lib/python3.7/site-packages (from requests->torchvision) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./ipeo_venv/lib/python3.7/site-packages (from requests->torchvision) (1.26.12)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in ./ipeo_venv/lib/python3.7/site-packages (from requests->torchvision) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./ipeo_venv/lib/python3.7/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./ipeo_venv/lib/python3.7/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.1)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25hCollecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (148 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.0/148.0 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting asynctest==0.13.0\n",
      "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./ipeo_venv/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (22.1.0)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.8.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (231 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.3/231.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in ./ipeo_venv/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.10.0)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting termcolor\n",
      "  Downloading termcolor-2.1.0-py3-none-any.whl (5.8 kB)\n",
      "Building wheels for collected packages: fire\n",
      "  Building wheel for fire (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fire: filename=fire-0.4.0-py2.py3-none-any.whl size=115928 sha256=56a8c6d51921e7d8a6390ea9ffdc851b043a9057ae4977d1532d6c96cdb114d3\n",
      "  Stored in directory: /home/atexier/.cache/pip/wheels/83/21/65/2ac62db55efa6e6edfad09f4e315aa82a35ab138f51e784fb1\n",
      "Successfully built fire\n",
      "Installing collected packages: tensorboard-plugin-wit, pyasn1, werkzeug, termcolor, tensorboard-data-server, rsa, PyYAML, pyasn1-modules, protobuf, oauthlib, multidict, grpcio, fsspec, frozenlist, cachetools, asynctest, async-timeout, absl-py, yarl, requests-oauthlib, markdown, google-auth, fire, aiosignal, lightning-utilities, google-auth-oauthlib, aiohttp, torchtext, torchmetrics, tensorboard, pytorch_lightning\n",
      "Successfully installed PyYAML-6.0 absl-py-1.3.0 aiohttp-3.8.3 aiosignal-1.3.1 async-timeout-4.0.2 asynctest-0.13.0 cachetools-5.2.0 fire-0.4.0 frozenlist-1.3.3 fsspec-2022.11.0 google-auth-2.14.1 google-auth-oauthlib-0.4.6 grpcio-1.50.0 lightning-utilities-0.3.0 markdown-3.4.1 multidict-6.0.2 oauthlib-3.2.2 protobuf-3.20.3 pyasn1-0.4.8 pyasn1-modules-0.2.8 pytorch_lightning-1.8.2 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.11.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 termcolor-2.1.0 torchmetrics-0.10.3 torchtext-0.14.0 werkzeug-2.2.2 yarl-1.8.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!pip install torch torchvision torchtext pytorch_lightning tensorboard matplotlib tqdm wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7378ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b61cc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as T\n",
    "import numpy as np \n",
    "import csv\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "from torch import nn\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f3b781",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b678862e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import os\n",
    "import zipfile\n",
    "if not os.path.exists(os.getcwd()+\"/ipeo_data\"):\n",
    "    with zipfile.ZipFile(os.getcwd()+\"/ipeo_data.zip\", 'r') as zip_ref:\n",
    "        zip_ref.extractall()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e394c13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = open(os.getcwd()+\"/ipeo_data/splits/train.csv\")\n",
    "train_csv  = csv.reader(train_csv)\n",
    "test_csv = open(os.getcwd()+\"/ipeo_data/splits/test.csv\")\n",
    "test_csv  = csv.reader(test_csv)\n",
    "val_csv = open(os.getcwd()+\"/ipeo_data/splits/val.csv\")\n",
    "val_csv  = csv.reader(val_csv)\n",
    "### CAREFUL need to remove the \"25595_11025_label\" from the validation dataset. Empty image ?\n",
    "### remove direcly in the val excel fil (row = 629)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c833962e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3872783",
   "metadata": {},
   "source": [
    "## Set up the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bf4a2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "\"\"\"CLASS rocks (1), scree (2), sparse rocks (3), water (4), glacier and permanent snow (5), forest(6), sparse forest(7),\n",
    "grasslands and others (8).\"\"\"\n",
    "\n",
    "class Alpine(Dataset):\n",
    "\n",
    "    # mapping between label class names and indices\n",
    "    LABEL_CLASSES = {\n",
    "      'rocks': \t\t  1,\n",
    "      'scree': \t\t\t    2,\n",
    "      'sparse_rocks': \t  3,\n",
    "      'water': \t\t\t\t      4,\n",
    "      'glacier_and_permanent_snow': \t\t\t    5,\n",
    "      'forest': \t\t\t    6,\n",
    "      'sparse_forest':   7,\n",
    "      'grasslands_and_others': \t\t\t\t    8,\n",
    "      \n",
    "    }\n",
    "\n",
    "    def __init__(self, transforms=None, split='train'):\n",
    "        self.transforms = transforms\n",
    "        #only for label_image\n",
    "        transforms_label = T.Compose([\n",
    "        T.ToTensor()\n",
    "        ])\n",
    "        self.transforms_label = transforms_label\n",
    "        \n",
    "        # prepare data\n",
    "        self.data = []                                  # list of tuples of (image path, label class)\n",
    "        # get images with correct index according to dataset split\n",
    "        if split=='train':\n",
    "            data_csv = open(os.getcwd()+\"/ipeo_data/splits/train.csv\")\n",
    "            data_csv  = csv.reader(data_csv)\n",
    "        if split=='test':\n",
    "            data_csv = open(os.getcwd()+\"/ipeo_data/splits/test.csv\")\n",
    "            data_csv  = csv.reader(data_csv)\n",
    "        if split=='val':\n",
    "            data_csv = open(os.getcwd()+\"/ipeo_data/splits/val.csv\")\n",
    "            data_csv  = csv.reader(data_csv)\n",
    "            \n",
    "        for row in data_csv :\n",
    "            img_name = os.getcwd()+\"/ipeo_data/rgb/\"+row[0]+\"_rgb.tif\"\n",
    "            img_label_name = os.getcwd()+\"/ipeo_data/alpine_label/\"+row[0]+\"_label.tif\"   \n",
    "        # example format: 'baseFolder/agricultural/agricultural07.tif'\n",
    "            self.data.append((\n",
    "                img_name,\n",
    "                img_label_name          # get index for label class\n",
    "            ))\n",
    "\n",
    "\n",
    "    #TODO: please provide the remaining functions required for the torch.utils.data.Dataset class.\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "    def __getitem__(self, x):\n",
    "        img_name, img_label_name = self.data[x]\n",
    "    \n",
    "        img = Image.open(img_name)\n",
    "        img_label = Image.open(img_label_name)\n",
    "        \n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "            img_label = self.transforms_label(img_label)\n",
    "        return img,img_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4816b2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset of length 7357\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d18e690714a546ae9e131a413f149611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='idx', options=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# initialize the dataset (call the constructor __init__)\n",
    "\n",
    "dataset = Alpine()\n",
    "print(f\"dataset of length {len(dataset)}\")\n",
    "# plot individual samples\n",
    "from ipywidgets import interact\n",
    "@interact(idx=range(100))\n",
    "def plot_sample(idx=0):\n",
    "    img, img_label = dataset[idx]\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(img)\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(img_label)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ae0a2d",
   "metadata": {},
   "source": [
    "### Find the mean and stf of the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2cc6ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nGOT: \\nmean: tensor([0.4572, 0.5079, 0.4388])\\nstd:  tensor([0.2366, 0.2141, 0.1992])\\nUse in normalisze transforms\\n\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transforms_train = T.Compose([\n",
    "  T.ToTensor()\n",
    "])\n",
    "\n",
    "# dataset\n",
    "train_dataset = Alpine(transforms=transforms_train, split='train')\n",
    "test_dataset = Alpine(transforms=transforms_train, split='test')\n",
    "val_dataset = Alpine(transforms=transforms_train, split='val')\n",
    "\n",
    "# data loader\n",
    "train_loader = DataLoader(train_dataset, \n",
    "                          batch_size  = 16, \n",
    "                          shuffle     = False, \n",
    "                          num_workers = 1,\n",
    "                          pin_memory  = True)\n",
    "test_loader = DataLoader(test_dataset, \n",
    "                          batch_size  = 16, \n",
    "                          shuffle     = False, \n",
    "                          num_workers = 1,\n",
    "                          pin_memory  = True)\n",
    "val_loader = DataLoader(val_dataset, \n",
    "                          batch_size  = 16, \n",
    "                          shuffle     = False, \n",
    "                          num_workers = 1,\n",
    "                          pin_memory  = True)\n",
    "\n",
    "def mean_std():\n",
    "    ####### COMPUTE MEAN / STD\n",
    "\n",
    "    # placeholders\n",
    "    psum    = torch.tensor([0.0, 0.0, 0.0])\n",
    "    psum_sq = torch.tensor([0.0, 0.0, 0.0])\n",
    "\n",
    "    #The first two steps are done in the snippet below. Note that we set axis = [0, 2, 3] \n",
    "    #to compute mean values with respect to axis 1. The dimensions of inputs is [batch_size x 3 x image_size x image_size],\n",
    "    #so we need to make sure we aggregate values per each RGB channel separately.\n",
    "\n",
    "    # loop through images\n",
    "    for img,img_label in tqdm(train_loader):\n",
    "        psum    += img.sum(axis        = [0, 2, 3])\n",
    "        psum_sq += (img ** 2).sum(axis = [0, 2, 3])\n",
    "\n",
    "    for img,img_label in tqdm(test_loader):\n",
    "        psum    += img.sum(axis        = [0, 2, 3])\n",
    "        psum_sq += (img ** 2).sum(axis = [0, 2, 3])\n",
    "\n",
    "    for img,img_label in tqdm(val_loader):\n",
    "        psum    += img.sum(axis        = [0, 2, 3])\n",
    "        psum_sq += (img ** 2).sum(axis = [0, 2, 3])\n",
    "\n",
    "    ####### FINAL CALCULATIONS\n",
    "\n",
    "    # image count\n",
    "    s = 0\n",
    "    for image in test_csv :\n",
    "        s+=1\n",
    "    for image in train_csv :\n",
    "        s+=1\n",
    "    for image in val_csv :\n",
    "        s+=1\n",
    "    # pixel count\n",
    "    image_size = train_dataset[0][0].shape #[3,400,400]     \n",
    "    count = s * image_size[1] * image_size[1]\n",
    "\n",
    "    # mean and std\n",
    "    total_mean = psum / count\n",
    "    total_var  = (psum_sq / count) - (total_mean ** 2)\n",
    "    total_std  = torch.sqrt(total_var)\n",
    "\n",
    "    # output\n",
    "    print('mean: '  + str(total_mean))\n",
    "    print('std:  '  + str(total_std))\n",
    "    return total_mean,total_std\n",
    "# mean,std = mean_std()\n",
    "\"\"\"\n",
    "GOT: \n",
    "mean: tensor([0.4572, 0.5079, 0.4388])\n",
    "std:  tensor([0.2366, 0.2141, 0.1992])\n",
    "Use in normalisze transforms\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb99a83",
   "metadata": {},
   "source": [
    "## Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64a067af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# mean and standard deviation of the dataset \n",
    "mean=torch.tensor([0.4572, 0.5079, 0.4388])\n",
    "std=torch.tensor([0.2366, 0.2141, 0.1992])\n",
    "# normalize image [0-1] (or 0-255) to zero-mean unit standard deviation\n",
    "normalize = T.Normalize(mean, std)\n",
    "# we invert normalization for plotting later\n",
    "std_inv = 1 / (std + 1e-7)\n",
    "unnormalize = T.Normalize(-mean * std_inv, std_inv)\n",
    "\n",
    "transforms_train = T.Compose([\n",
    "  #TODO: add your own transforms here\n",
    "  T.RandomResizedCrop((200, 200)),\n",
    "  T.RandomGrayscale(),\n",
    "  T.RandomHorizontalFlip(),\n",
    "  T.RandomApply([T.GaussianBlur(kernel_size=7)]),\n",
    "  T.RandomPosterize(bits=8),\n",
    "  T.RandomVerticalFlip(),\n",
    "  T.ColorJitter(),\n",
    "  T.Resize((224, 224)),\n",
    "  T.ToTensor(),\n",
    "  normalize\n",
    "])\n",
    "# we do not augment the validation dataset (aside from resizing and tensor casting)\n",
    "transforms_val = T.Compose([\n",
    "  T.Resize((224, 224)),\n",
    "  T.ToTensor(),\n",
    "  normalize\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564dfe59",
   "metadata": {},
   "source": [
    "## Model  Base on AlexNet + https://github.com/milesial/Pytorch-UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee67fd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        # if you have padding issues, see\n",
    "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
    "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e317372c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Full assembly of the parts to form the complete network \"\"\"\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=False):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = Down(512, 1024 // factor)\n",
    "        self.up1 = Up(1024, 512 // factor, bilinear)\n",
    "        self.up2 = Up(512, 256 // factor, bilinear)\n",
    "        self.up3 = Up(256, 128 // factor, bilinear)\n",
    "        self.up4 = Up(128, 64, bilinear)\n",
    "        self.outc = OutConv(64, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d5bac7",
   "metadata": {},
   "source": [
    "## Getloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f49249e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders(split):\n",
    "    \n",
    "    data_dataset = Alpine(transforms=transforms_train, split=split)\n",
    "\n",
    "\n",
    "    # data loader\n",
    "    data_loader = DataLoader(data_dataset, \n",
    "                              batch_size  = 64, \n",
    "                              shuffle     = True, \n",
    "                              num_workers = 1,\n",
    "                              pin_memory  = True)\n",
    "    return data_dataset, data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9df83458",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atexier/ipeo_venv/lib/python3.7/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    }
   ],
   "source": [
    " train_loader = get_dataloaders(\"train\")[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afd468f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 4.3780e-01,  4.2123e-01,  4.0465e-01,  ..., -1.3854e+00,\n",
      "           -1.4020e+00, -1.4186e+00],\n",
      "          [ 4.3780e-01,  4.0465e-01,  3.8808e-01,  ..., -1.4020e+00,\n",
      "           -1.4186e+00, -1.4351e+00],\n",
      "          [ 4.5438e-01,  4.2123e-01,  4.0465e-01,  ..., -1.4517e+00,\n",
      "           -1.4683e+00, -1.4849e+00],\n",
      "          ...,\n",
      "          [ 5.8698e-01,  6.0355e-01,  5.7040e-01,  ...,  7.8587e-01,\n",
      "            9.1847e-01,  1.0013e+00],\n",
      "          [ 5.2068e-01,  5.3725e-01,  4.8753e-01,  ...,  9.1847e-01,\n",
      "            1.0179e+00,  1.0676e+00],\n",
      "          [ 4.8753e-01,  4.8753e-01,  4.3780e-01,  ...,  9.6819e-01,\n",
      "            1.0345e+00,  1.0676e+00]],\n",
      "\n",
      "         [[ 2.6532e-01,  2.6532e-01,  2.4701e-01,  ..., -1.6945e+00,\n",
      "           -1.7129e+00, -1.7495e+00],\n",
      "          [ 2.8364e-01,  2.6532e-01,  2.4701e-01,  ..., -1.7129e+00,\n",
      "           -1.7495e+00, -1.7861e+00],\n",
      "          [ 3.0196e-01,  2.8364e-01,  2.6532e-01,  ..., -1.7678e+00,\n",
      "           -1.8044e+00, -1.8228e+00],\n",
      "          ...,\n",
      "          [ 4.6681e-01,  4.6681e-01,  4.4849e-01,  ...,  7.4155e-01,\n",
      "            8.8809e-01,  9.4304e-01],\n",
      "          [ 4.3017e-01,  4.3017e-01,  3.7522e-01,  ...,  8.6977e-01,\n",
      "            9.6135e-01,  1.0163e+00],\n",
      "          [ 3.9354e-01,  3.7522e-01,  3.2027e-01,  ...,  9.2472e-01,\n",
      "            9.9799e-01,  1.0346e+00]],\n",
      "\n",
      "         [[ 5.1394e-01,  4.9425e-01,  4.7457e-01,  ..., -1.1397e+00,\n",
      "           -1.1594e+00, -1.1791e+00],\n",
      "          [ 5.1394e-01,  4.9425e-01,  4.7457e-01,  ..., -1.1791e+00,\n",
      "           -1.1988e+00, -1.2185e+00],\n",
      "          [ 5.1394e-01,  4.9425e-01,  4.7457e-01,  ..., -1.2579e+00,\n",
      "           -1.2775e+00, -1.2972e+00],\n",
      "          ...,\n",
      "          [ 6.3206e-01,  6.3206e-01,  6.1237e-01,  ...,  9.0767e-01,\n",
      "            9.8642e-01,  1.0455e+00],\n",
      "          [ 5.9268e-01,  5.7300e-01,  5.5331e-01,  ...,  9.8642e-01,\n",
      "            1.0455e+00,  1.0848e+00],\n",
      "          [ 5.5331e-01,  5.3362e-01,  5.1394e-01,  ...,  1.0455e+00,\n",
      "            1.0652e+00,  1.0848e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2288e-01, -9.7127e-03, -1.0916e-01,  ..., -7.8872e-01,\n",
      "           -7.5557e-01, -5.2353e-01],\n",
      "          [ 6.8620e-03, -9.7127e-03, -5.9437e-02,  ..., -6.2298e-01,\n",
      "           -4.7380e-01, -2.0861e-01],\n",
      "          [ 4.0011e-02,  5.6586e-02, -7.6011e-02,  ..., -4.7380e-01,\n",
      "           -3.4121e-01, -2.0861e-01],\n",
      "          ...,\n",
      "          [-4.0750e-01, -2.4176e-01, -1.9203e-01,  ...,  1.4654e+00,\n",
      "            1.2831e+00,  1.4489e+00],\n",
      "          [-6.8927e-01, -4.2408e-01, -3.2463e-01,  ...,  1.5152e+00,\n",
      "            1.3328e+00,  1.4986e+00],\n",
      "          [-1.0705e+00, -8.0530e-01, -7.0585e-01,  ...,  1.3494e+00,\n",
      "            1.1008e+00,  1.2002e+00]],\n",
      "\n",
      "         [[-2.7740e-02,  8.8928e-03, -4.6057e-02,  ..., -5.7724e-01,\n",
      "           -3.2080e-01, -6.4373e-02],\n",
      "          [-1.7427e-01, -4.6057e-02, -9.4237e-03,  ..., -3.3912e-01,\n",
      "           -8.2690e-02,  1.1879e-01],\n",
      "          [-2.1091e-01, -2.7740e-02, -4.6057e-02,  ..., -1.5596e-01,\n",
      "           -4.6057e-02,  4.5526e-02],\n",
      "          ...,\n",
      "          [ 2.7209e-02,  1.0048e-01,  4.5526e-02,  ...,  1.3826e+00,\n",
      "            1.3094e+00,  1.3643e+00],\n",
      "          [-2.8417e-01, -6.4373e-02, -1.0101e-01,  ...,  1.4193e+00,\n",
      "            1.2361e+00,  1.2544e+00],\n",
      "          [-8.8862e-01, -4.4902e-01, -4.3070e-01,  ...,  1.2727e+00,\n",
      "            1.0529e+00,  1.1079e+00]],\n",
      "\n",
      "         [[-9.6346e-02, -4.3102e-01, -3.9164e-01,  ..., -2.5384e-01,\n",
      "           -7.8538e-01, -1.4547e+00],\n",
      "          [-1.5541e-01, -3.9164e-01, -2.7353e-01,  ..., -4.3102e-01,\n",
      "           -8.6412e-01, -1.2579e+00],\n",
      "          [-1.5541e-01, -3.1290e-01, -2.7353e-01,  ..., -6.6726e-01,\n",
      "           -8.6412e-01, -7.8538e-01],\n",
      "          ...,\n",
      "          [-8.4444e-01, -8.2475e-01, -7.4600e-01,  ...,  1.3605e+00,\n",
      "            1.3014e+00,  1.3801e+00],\n",
      "          [-1.1200e+00, -7.2632e-01, -5.8851e-01,  ...,  1.3408e+00,\n",
      "            1.2423e+00,  1.3408e+00],\n",
      "          [-1.2382e+00, -6.6726e-01, -5.2945e-01,  ...,  1.2423e+00,\n",
      "            1.0455e+00,  1.0848e+00]]],\n",
      "\n",
      "\n",
      "        [[[-1.3357e+00, -1.3357e+00, -1.3357e+00,  ...,  1.5603e-01,\n",
      "            1.5603e-01,  1.3946e-01],\n",
      "          [-1.3357e+00, -1.3357e+00, -1.3357e+00,  ...,  1.7261e-01,\n",
      "            1.7261e-01,  1.7261e-01],\n",
      "          [-1.3357e+00, -1.3357e+00, -1.3357e+00,  ...,  1.8918e-01,\n",
      "            1.8918e-01,  1.8918e-01],\n",
      "          ...,\n",
      "          [-7.6011e-02, -9.2586e-02, -1.5888e-01,  ...,  2.0290e+00,\n",
      "            2.0455e+00,  2.0621e+00],\n",
      "          [-9.2586e-02, -1.0916e-01, -1.5888e-01,  ...,  2.0455e+00,\n",
      "            2.0621e+00,  2.0787e+00],\n",
      "          [-9.2586e-02, -1.0916e-01, -1.5888e-01,  ...,  2.0621e+00,\n",
      "            2.0787e+00,  2.0787e+00]],\n",
      "\n",
      "         [[-1.7129e+00, -1.7129e+00, -1.7129e+00,  ..., -6.4373e-02,\n",
      "           -6.4373e-02, -8.2690e-02],\n",
      "          [-1.7129e+00, -1.7129e+00, -1.7129e+00,  ..., -4.6057e-02,\n",
      "           -4.6057e-02, -4.6057e-02],\n",
      "          [-1.7129e+00, -1.7129e+00, -1.7129e+00,  ..., -2.7740e-02,\n",
      "           -2.7740e-02, -2.7740e-02],\n",
      "          ...,\n",
      "          [-3.2080e-01, -3.3912e-01, -4.1239e-01,  ...,  2.0054e+00,\n",
      "            2.0237e+00,  2.0420e+00],\n",
      "          [-3.3912e-01, -3.5744e-01, -4.1239e-01,  ...,  2.0237e+00,\n",
      "            2.0420e+00,  2.0603e+00],\n",
      "          [-3.3912e-01, -3.5744e-01, -4.1239e-01,  ...,  2.0420e+00,\n",
      "            2.0603e+00,  2.0603e+00]],\n",
      "\n",
      "         [[-1.4941e+00, -1.4941e+00, -1.4941e+00,  ...,  2.7770e-01,\n",
      "            2.7770e-01,  2.5801e-01],\n",
      "          [-1.4941e+00, -1.4941e+00, -1.4941e+00,  ...,  2.9739e-01,\n",
      "            2.9739e-01,  2.9739e-01],\n",
      "          [-1.4941e+00, -1.4941e+00, -1.4941e+00,  ...,  3.1707e-01,\n",
      "            3.1707e-01,  3.1707e-01],\n",
      "          ...,\n",
      "          [ 2.0868e-03, -1.7600e-02, -9.6346e-02,  ...,  2.5023e+00,\n",
      "            2.5220e+00,  2.5417e+00],\n",
      "          [-1.7600e-02, -3.7286e-02, -9.6346e-02,  ...,  2.5220e+00,\n",
      "            2.5417e+00,  2.5613e+00],\n",
      "          [-1.7600e-02, -3.7286e-02, -9.6346e-02,  ...,  2.5417e+00,\n",
      "            2.5613e+00,  2.5613e+00]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.6838e+00, -1.7169e+00, -1.7501e+00,  ..., -2.5833e-01,\n",
      "           -9.2586e-02, -1.4231e-01],\n",
      "          [-1.6672e+00, -1.6672e+00, -1.6838e+00,  ..., -2.2518e-01,\n",
      "           -1.0916e-01, -7.6011e-02],\n",
      "          [-1.7003e+00, -1.7003e+00, -1.6506e+00,  ..., -1.9203e-01,\n",
      "           -1.7546e-01, -2.0861e-01],\n",
      "          ...,\n",
      "          [-1.0916e-01, -2.7491e-01, -2.0861e-01,  ...,  1.2288e-01,\n",
      "            1.8918e-01,  5.6586e-02],\n",
      "          [-4.0750e-01, -5.0695e-01, -4.2408e-01,  ...,  1.0631e-01,\n",
      "            1.0631e-01,  1.0631e-01],\n",
      "          [-2.7491e-01, -1.2574e-01, -2.6287e-02,  ...,  1.0631e-01,\n",
      "            5.6586e-02,  5.6586e-02]],\n",
      "\n",
      "         [[-2.1341e+00, -2.1158e+00, -2.1525e+00,  ...,  1.1879e-01,\n",
      "            1.1879e-01,  1.3711e-01],\n",
      "          [-2.1341e+00, -2.1525e+00, -2.0975e+00,  ...,  8.2159e-02,\n",
      "            1.5543e-01,  1.9206e-01],\n",
      "          [-2.1525e+00, -2.2257e+00, -2.1708e+00,  ...,  1.0048e-01,\n",
      "            2.1037e-01,  2.4701e-01],\n",
      "          ...,\n",
      "          [ 2.4701e-01,  3.0196e-01,  3.7522e-01,  ...,  2.2869e-01,\n",
      "            2.2869e-01,  2.1037e-01],\n",
      "          [ 1.9206e-01,  2.2869e-01,  3.0196e-01,  ...,  2.6532e-01,\n",
      "            2.4701e-01,  2.8364e-01],\n",
      "          [ 3.3859e-01,  2.8364e-01,  3.0196e-01,  ...,  3.5691e-01,\n",
      "            2.8364e-01,  1.5543e-01]],\n",
      "\n",
      "         [[-1.6713e+00, -1.8288e+00, -1.6122e+00,  ..., -5.8851e-01,\n",
      "           -6.0820e-01, -6.0820e-01],\n",
      "          [-1.6319e+00, -1.6713e+00, -1.7500e+00,  ..., -5.6882e-01,\n",
      "           -4.5070e-01, -1.9478e-01],\n",
      "          [-1.5532e+00, -1.5138e+00, -1.7697e+00,  ..., -5.0976e-01,\n",
      "           -2.9321e-01, -2.9321e-01],\n",
      "          ...,\n",
      "          [-7.6660e-02, -1.1603e-01, -3.9164e-01,  ..., -1.1603e-01,\n",
      "           -2.9321e-01, -4.3102e-01],\n",
      "          [-4.3102e-01, -3.9164e-01, -5.6882e-01,  ..., -2.1447e-01,\n",
      "           -4.3102e-01, -3.5227e-01],\n",
      "          [-2.5384e-01, -3.1290e-01, -4.1133e-01,  ..., -2.7353e-01,\n",
      "           -5.8851e-01, -3.7196e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.5180e+00, -1.4351e+00, -1.5014e+00,  ..., -1.4849e+00,\n",
      "           -1.5014e+00, -1.4683e+00],\n",
      "          [-1.5677e+00, -1.4849e+00, -1.5512e+00,  ..., -1.4517e+00,\n",
      "           -1.4683e+00, -1.4849e+00],\n",
      "          [-1.5512e+00, -1.5014e+00, -1.5346e+00,  ..., -1.4683e+00,\n",
      "           -1.4683e+00, -1.5014e+00],\n",
      "          ...,\n",
      "          [ 1.1008e+00,  9.6819e-01,  1.0013e+00,  ...,  6.5327e-01,\n",
      "            8.3560e-01,  1.2002e+00],\n",
      "          [ 1.2168e+00,  9.6819e-01,  8.6875e-01,  ...,  6.8642e-01,\n",
      "            1.0842e+00,  1.3494e+00],\n",
      "          [ 1.2002e+00,  1.0345e+00,  9.3504e-01,  ...,  9.1847e-01,\n",
      "            1.2997e+00,  1.4157e+00]],\n",
      "\n",
      "         [[-1.6762e+00, -1.8594e+00, -1.9143e+00,  ..., -1.9143e+00,\n",
      "           -1.8594e+00, -1.9143e+00],\n",
      "          [-1.8594e+00, -1.8594e+00, -1.8960e+00,  ..., -1.8411e+00,\n",
      "           -1.8777e+00, -1.8411e+00],\n",
      "          [-1.8777e+00, -1.9143e+00, -1.8777e+00,  ..., -1.8228e+00,\n",
      "           -1.8594e+00, -1.7495e+00],\n",
      "          ...,\n",
      "          [ 8.8809e-01,  8.8809e-01,  9.0640e-01,  ...,  5.9502e-01,\n",
      "            7.4155e-01,  9.7967e-01],\n",
      "          [ 8.6977e-01,  8.6977e-01,  8.5145e-01,  ...,  5.5839e-01,\n",
      "            7.9650e-01,  1.0529e+00],\n",
      "          [ 8.6977e-01,  8.6977e-01,  8.1482e-01,  ...,  7.0492e-01,\n",
      "            8.6977e-01,  1.0713e+00]],\n",
      "\n",
      "         [[-1.0019e+00, -1.4547e+00, -1.3563e+00,  ..., -1.1791e+00,\n",
      "           -1.0413e+00, -9.8224e-01],\n",
      "          [-1.0216e+00, -1.4153e+00, -1.2972e+00,  ..., -1.1791e+00,\n",
      "           -9.8224e-01, -8.0506e-01],\n",
      "          [-1.1594e+00, -1.3563e+00, -1.1594e+00,  ..., -1.3366e+00,\n",
      "           -1.0216e+00, -7.0663e-01],\n",
      "          ...,\n",
      "          [ 8.8798e-01,  1.0061e+00,  1.0061e+00,  ...,  6.3206e-01,\n",
      "            7.1080e-01,  8.0924e-01],\n",
      "          [ 9.6673e-01,  1.0061e+00,  9.4704e-01,  ...,  5.5331e-01,\n",
      "            6.9112e-01,  7.8955e-01],\n",
      "          [ 1.0258e+00,  1.0061e+00,  9.8642e-01,  ...,  5.7300e-01,\n",
      "            7.5018e-01,  8.8798e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.2463e-01, -2.2518e-01, -2.7491e-01,  ..., -1.7546e-01,\n",
      "           -1.5888e-01, -2.5833e-01],\n",
      "          [-5.2353e-01, -2.5833e-01, -2.9148e-01,  ..., -9.2586e-02,\n",
      "           -1.0916e-01, -2.2518e-01],\n",
      "          [-5.7325e-01, -2.5833e-01, -3.0806e-01,  ..., -2.6287e-02,\n",
      "           -1.5888e-01, -2.9148e-01],\n",
      "          ...,\n",
      "          [-1.4351e+00, -1.1368e+00, -1.0705e+00,  ...,  1.2288e-01,\n",
      "            4.8753e-01,  5.6586e-02],\n",
      "          [-1.4517e+00, -1.1202e+00, -9.7104e-01,  ...,  1.5603e-01,\n",
      "            3.8808e-01, -1.9203e-01],\n",
      "          [-1.5512e+00, -1.3025e+00, -1.0871e+00,  ...,  2.0576e-01,\n",
      "            4.5438e-01, -2.5833e-01]],\n",
      "\n",
      "         [[-1.9259e-01, -2.6586e-01, -3.0249e-01,  ...,  1.7374e-01,\n",
      "            1.0048e-01, -1.5596e-01],\n",
      "          [-3.5744e-01, -3.2080e-01, -3.2080e-01,  ...,  1.3711e-01,\n",
      "            4.5526e-02, -1.7427e-01],\n",
      "          [-3.7575e-01, -3.2080e-01, -3.5744e-01,  ...,  1.0048e-01,\n",
      "            2.7209e-02, -1.0101e-01],\n",
      "          ...,\n",
      "          [-1.4931e+00, -1.3282e+00, -1.0351e+00,  ...,  2.6532e-01,\n",
      "            4.3017e-01,  2.6532e-01],\n",
      "          [-1.4015e+00, -1.2549e+00, -9.8020e-01,  ...,  2.6532e-01,\n",
      "            3.3859e-01,  8.2159e-02],\n",
      "          [-1.4564e+00, -1.3099e+00, -1.0535e+00,  ...,  3.3859e-01,\n",
      "            3.5691e-01,  2.7209e-02]],\n",
      "\n",
      "         [[-2.7353e-01, -2.9321e-01, -3.9164e-01,  ..., -1.1603e-01,\n",
      "           -1.5541e-01, -3.1290e-01],\n",
      "          [-4.5070e-01, -2.3415e-01, -3.3259e-01,  ..., -1.9478e-01,\n",
      "           -1.9478e-01, -2.7353e-01],\n",
      "          [-5.0976e-01, -2.5384e-01, -2.5384e-01,  ..., -3.1290e-01,\n",
      "           -2.7353e-01, -2.9321e-01],\n",
      "          ...,\n",
      "          [-9.2318e-01, -8.6412e-01, -7.2632e-01,  ..., -2.1447e-01,\n",
      "           -1.3572e-01, -7.6660e-02],\n",
      "          [-8.2475e-01, -7.8538e-01, -7.0663e-01,  ..., -1.3572e-01,\n",
      "           -1.5541e-01, -9.6346e-02],\n",
      "          [-7.2632e-01, -7.2632e-01, -7.4600e-01,  ..., -5.6973e-02,\n",
      "           -9.6346e-02, -1.5541e-01]]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        print(data)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0c593cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer, scheduler, criterion, train_loader, epoch, device):\n",
    "    ### SOLUTION\n",
    "    model.train()\n",
    "    loss_history = []\n",
    "    accuracy_history = []\n",
    "    lr_history = []\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        print(data.shape)\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        #pred = output.argmax(dim=1, keepdim=True)\n",
    "        #correct = pred.eq(target.view_as(pred)).sum().item()\n",
    "        accuracy_float = (predictions == ground_truth).mean()\n",
    "        loss_float = loss.item()\n",
    "        \n",
    "\n",
    "        loss_history.append(loss_float)\n",
    "        accuracy_history.append(accuracy_float)\n",
    "        lr_history.append(scheduler.get_last_lr()[0])\n",
    "        if batch_idx % (len(train_loader.dataset) // len(data) // 10) == 0:\n",
    "            print(\n",
    "                f\"Train Epoch: {epoch}-{batch_idx:03d} \"\n",
    "                f\"batch_loss={loss_float:0.2e} \"\n",
    "                f\"batch_acc={accuracy_float:0.3f} \"\n",
    "                f\"lr={scheduler.get_last_lr()[0]:0.3e} \"\n",
    "            )\n",
    "\n",
    "    return loss_history, accuracy_history, lr_history\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, device, val_loader, criterion):\n",
    "    model.eval()  # Important: eval mode (affects dropout, batch norm etc)\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in val_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        test_loss += criterion(output, target).item() * len(data)\n",
    "        pred = output.argmax(\n",
    "            dim=1, keepdim=True\n",
    "        )  # get the index of the max log-probability\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(val_loader.dataset)\n",
    "\n",
    "    print(\n",
    "        \"Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\".format(\n",
    "            test_loss,\n",
    "            correct,\n",
    "            len(val_loader.dataset),\n",
    "            100.0 * correct / len(val_loader.dataset),\n",
    "        )\n",
    "    )\n",
    "    return test_loss, correct / len(val_loader.dataset)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_predictions(model, device, val_loader, criterion, num=None):\n",
    "    model.eval()\n",
    "    points = []\n",
    "    for data, target in val_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "\n",
    "        data = np.split(data.cpu().numpy(), len(data))\n",
    "        loss = np.split(loss.cpu().numpy(), len(data))\n",
    "        pred = np.split(pred.cpu().numpy(), len(data))\n",
    "        target = np.split(target.cpu().numpy(), len(data))\n",
    "        points.extend(zip(data, loss, pred, target))\n",
    "\n",
    "        if num is not None and len(points) > num:\n",
    "            break\n",
    "\n",
    "    return points\n",
    "\n",
    "\n",
    "def run_training(\n",
    "    model_factory,\n",
    "    num_epochs,\n",
    "    optimizer_kwargs,\n",
    "    device=\"cuda\",\n",
    "):\n",
    "    # ===== Data Loading =====\n",
    "    train_loader = get_dataloaders(\"train\")[1]\n",
    "    val_loader = get_dataloaders(\"val\")[1]\n",
    "\n",
    "    # ===== Model, Optimizer and Criterion =====\n",
    "    model = UNet(3,8)\n",
    "    model = model.to(device=device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), **optimizer_kwargs)\n",
    "    criterion = torch.nn.functional.cross_entropy\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer,\n",
    "        T_max=(len(train_loader.dataset) * num_epochs) // train_loader.batch_size,\n",
    "    )\n",
    "\n",
    "    # ===== Train Model =====\n",
    "    lr_history = []\n",
    "    train_loss_history = []\n",
    "    train_acc_history = []\n",
    "    val_loss_history = []\n",
    "    val_acc_history = []\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        train_loss, train_acc, lrs = train_epoch(\n",
    "            model, optimizer, scheduler, criterion, train_loader, epoch, device\n",
    "        )\n",
    "        train_loss_history.extend(train_loss)\n",
    "        train_acc_history.extend(train_acc)\n",
    "        lr_history.extend(lrs)\n",
    "\n",
    "        val_loss, val_acc = validate(model, device, val_loader, criterion)\n",
    "        val_loss_history.append(val_loss)\n",
    "        val_acc_history.append(val_acc)\n",
    "\n",
    "    # ===== Plot training curves =====\n",
    "    n_train = len(train_acc_history)\n",
    "    t_train = num_epochs * np.arange(n_train) / n_train\n",
    "    t_val = np.arange(1, num_epochs + 1)\n",
    "\n",
    "    plt.figure(figsize=(6.4 * 3, 4.8))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(t_train, train_acc_history, label=\"Train\")\n",
    "    plt.plot(t_val, val_acc_history, label=\"Val\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(t_train, train_loss_history, label=\"Train\")\n",
    "    plt.plot(t_val, val_loss_history, label=\"Val\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(t_train, lr_history)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Learning Rate\")\n",
    "\n",
    "    # ===== Plot low/high loss predictions on validation set =====\n",
    "    points = get_predictions(\n",
    "        model,\n",
    "        device,\n",
    "        val_loader,\n",
    "        partial(torch.nn.functional.cross_entropy, reduction=\"none\"),\n",
    "    )\n",
    "    points.sort(key=lambda x: x[1])\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    for k in range(5):\n",
    "        plt.subplot(2, 5, k + 1)\n",
    "        plt.imshow(points[k][0][0, 0], cmap=\"gray\")\n",
    "        plt.title(f\"true={int(points[k][3])} pred={int(points[k][2])}\")\n",
    "        plt.subplot(2, 5, 5 + k + 1)\n",
    "        plt.imshow(points[-k - 1][0][0, 0], cmap=\"gray\")\n",
    "        plt.title(f\"true={int(points[-k-1][3])} pred={int(points[-k-1][2])}\")\n",
    "\n",
    "    return sum(train_acc) / len(train_acc), val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c18e8c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 224, 224])\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 196.00 MiB (GPU 0; 31.75 GiB total capacity; 30.09 GiB already allocated; 161.50 MiB free; 30.41 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m/tmp/1134100/ipykernel_1578/729582217.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0moptimizer_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m )\n",
      "\u001b[0;32m/tmp/1134100/ipykernel_1578/709903759.py\u001b[0m in \u001b[0;36mrun_training\u001b[0;34m(model_factory, num_epochs, optimizer_kwargs, device)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         train_loss, train_acc, lrs = train_epoch(\n\u001b[0;32m--> 114\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         )\n\u001b[1;32m    116\u001b[0m         \u001b[0mtrain_loss_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/1134100/ipykernel_1578/709903759.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, optimizer, scheduler, criterion, train_loader, epoch, device)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ipeo_venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/1134100/ipykernel_1578/1836838231.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mx3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mx4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mx5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ipeo_venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/1134100/ipykernel_1578/1549376752.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxpool_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ipeo_venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ipeo_venv/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ipeo_venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/1134100/ipykernel_1578/1549376752.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ipeo_venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ipeo_venv/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ipeo_venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ipeo_venv/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0mbn_training\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mexponential_average_factor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         )\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ipeo_venv/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2450\u001b[0m     return torch.batch_norm(\n\u001b[0;32m-> 2451\u001b[0;31m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2452\u001b[0m     )\n\u001b[1;32m   2453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 196.00 MiB (GPU 0; 31.75 GiB total capacity; 30.09 GiB already allocated; 161.50 MiB free; 30.41 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "image_size = 400\n",
    "model_factory = UNet\n",
    "num_epochs = 1\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "optimizer_kwargs = dict(\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-2,\n",
    ")\n",
    "\n",
    "run_training(\n",
    "    model_factory=UNet,\n",
    "    num_epochs=num_epochs,\n",
    "    optimizer_kwargs=optimizer_kwargs,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff53fcc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3fb06c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb594057",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd8a345",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbe4d13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9587d218",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def training_step(batch, model, optimizer, device=\"cuda\"):\n",
    "    # TODO fill this function with the training step code\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    model.zero_grad()\n",
    "    \n",
    "    # TODO retrieve image and label from the batch\n",
    "    x, y = batch\n",
    "    \n",
    "    # TODO move model and code to GPU\n",
    "    model = model.to(device)\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    \n",
    "    # TODO forward pass\n",
    "    y_hat =  model(x)\n",
    "    \n",
    "    # TODO loss calculation\n",
    "    loss = criterion(y_hat,y)\n",
    "  \n",
    "    # TODO implement backprop and model update\n",
    "     # backpropoagation of gradients\n",
    "     # update model parameters\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # lets also calculate accuracy for fun\n",
    "    # FYI\n",
    "    # .cpu() moves the data back to cpu (if on GPU)\n",
    "    # .detach() removes gradients (we dont need them for accuracy)\n",
    "    # .numpy() converts the tensor to numpy for better handling later\n",
    "    predictions = y_hat.argmax(1).cpu().detach().numpy()\n",
    "    ground_truth = y.cpu().detach().numpy()\n",
    "    \n",
    "    # accuracy is the mean of correct (1) and incorrect (0) classifications\n",
    "    accuracy = (predictions == ground_truth).mean()\n",
    "  \n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b677cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a5c37f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181eb246",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f020886",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b68f0c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
