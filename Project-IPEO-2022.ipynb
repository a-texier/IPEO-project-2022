{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17c64ef2",
   "metadata": {},
   "source": [
    "## import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6346fad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in ./ipeo_venv/lib/python3.7/site-packages (1.13.0)\n",
      "Requirement already satisfied: torchvision in ./ipeo_venv/lib/python3.7/site-packages (0.14.0)\n",
      "Collecting torchtext\n",
      "  Downloading torchtext-0.14.0-cp37-cp37m-manylinux1_x86_64.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pytorch_lightning\n",
      "  Downloading pytorch_lightning-1.8.2-py3-none-any.whl (798 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.7/798.7 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard\n",
      "  Downloading tensorboard-2.11.0-py3-none-any.whl (6.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in ./ipeo_venv/lib/python3.7/site-packages (3.5.3)\n",
      "Requirement already satisfied: tqdm in ./ipeo_venv/lib/python3.7/site-packages (4.64.1)\n",
      "Requirement already satisfied: wget in ./ipeo_venv/lib/python3.7/site-packages (3.2)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in ./ipeo_venv/lib/python3.7/site-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in ./ipeo_venv/lib/python3.7/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in ./ipeo_venv/lib/python3.7/site-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in ./ipeo_venv/lib/python3.7/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: typing-extensions in ./ipeo_venv/lib/python3.7/site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: wheel in ./ipeo_venv/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.38.4)\n",
      "Requirement already satisfied: setuptools in ./ipeo_venv/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (41.2.0)\n",
      "Requirement already satisfied: requests in ./ipeo_venv/lib/python3.7/site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: numpy in ./ipeo_venv/lib/python3.7/site-packages (from torchvision) (1.21.6)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./ipeo_venv/lib/python3.7/site-packages (from torchvision) (9.3.0)\n",
      "Requirement already satisfied: packaging>=17.0 in ./ipeo_venv/lib/python3.7/site-packages (from pytorch_lightning) (21.3)\n",
      "Collecting torchmetrics>=0.7.0\n",
      "  Downloading torchmetrics-0.10.3-py3-none-any.whl (529 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m529.7/529.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting lightning-utilities==0.3.*\n",
      "  Downloading lightning_utilities-0.3.0-py3-none-any.whl (15 kB)\n",
      "Collecting fsspec[http]>2021.06.0\n",
      "  Downloading fsspec-2022.11.0-py3-none-any.whl (139 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.5/139.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting PyYAML>=5.4\n",
      "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m596.3/596.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting fire\n",
      "  Downloading fire-0.4.0.tar.gz (87 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.7/87.7 kB\u001b[0m \u001b[31m935.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting absl-py>=0.4\n",
      "  Downloading absl_py-1.3.0-py3-none-any.whl (124 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.6/124.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.14.1-py2.py3-none-any.whl (175 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.4/175.4 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting werkzeug>=1.0.1\n",
      "  Downloading Werkzeug-2.2.2-py3-none-any.whl (232 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.7/232.7 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting grpcio>=1.24.3\n",
      "  Downloading grpcio-1.50.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.3/93.3 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting protobuf<4,>=3.9.2\n",
      "  Downloading protobuf-3.20.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in ./ipeo_venv/lib/python3.7/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./ipeo_venv/lib/python3.7/site-packages (from matplotlib) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./ipeo_venv/lib/python3.7/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: cycler>=0.10 in ./ipeo_venv/lib/python3.7/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in ./ipeo_venv/lib/python3.7/site-packages (from matplotlib) (3.0.9)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1\n",
      "  Downloading aiohttp-3.8.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (948 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m948.0/948.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
      "Requirement already satisfied: six>=1.9.0 in ./ipeo_venv/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.16.0)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in ./ipeo_venv/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard) (5.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./ipeo_venv/lib/python3.7/site-packages (from requests->torchvision) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./ipeo_venv/lib/python3.7/site-packages (from requests->torchvision) (1.26.12)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in ./ipeo_venv/lib/python3.7/site-packages (from requests->torchvision) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./ipeo_venv/lib/python3.7/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./ipeo_venv/lib/python3.7/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.1)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25hCollecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (148 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.0/148.0 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting asynctest==0.13.0\n",
      "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./ipeo_venv/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (22.1.0)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.8.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (231 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.3/231.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in ./ipeo_venv/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.10.0)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting termcolor\n",
      "  Downloading termcolor-2.1.0-py3-none-any.whl (5.8 kB)\n",
      "Building wheels for collected packages: fire\n",
      "  Building wheel for fire (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fire: filename=fire-0.4.0-py2.py3-none-any.whl size=115928 sha256=56a8c6d51921e7d8a6390ea9ffdc851b043a9057ae4977d1532d6c96cdb114d3\n",
      "  Stored in directory: /home/atexier/.cache/pip/wheels/83/21/65/2ac62db55efa6e6edfad09f4e315aa82a35ab138f51e784fb1\n",
      "Successfully built fire\n",
      "Installing collected packages: tensorboard-plugin-wit, pyasn1, werkzeug, termcolor, tensorboard-data-server, rsa, PyYAML, pyasn1-modules, protobuf, oauthlib, multidict, grpcio, fsspec, frozenlist, cachetools, asynctest, async-timeout, absl-py, yarl, requests-oauthlib, markdown, google-auth, fire, aiosignal, lightning-utilities, google-auth-oauthlib, aiohttp, torchtext, torchmetrics, tensorboard, pytorch_lightning\n",
      "Successfully installed PyYAML-6.0 absl-py-1.3.0 aiohttp-3.8.3 aiosignal-1.3.1 async-timeout-4.0.2 asynctest-0.13.0 cachetools-5.2.0 fire-0.4.0 frozenlist-1.3.3 fsspec-2022.11.0 google-auth-2.14.1 google-auth-oauthlib-0.4.6 grpcio-1.50.0 lightning-utilities-0.3.0 markdown-3.4.1 multidict-6.0.2 oauthlib-3.2.2 protobuf-3.20.3 pyasn1-0.4.8 pyasn1-modules-0.2.8 pytorch_lightning-1.8.2 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.11.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 termcolor-2.1.0 torchmetrics-0.10.3 torchtext-0.14.0 werkzeug-2.2.2 yarl-1.8.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!pip install torch torchvision torchtext pytorch_lightning tensorboard matplotlib tqdm wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7378ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b61cc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f3b781",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b678862e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import os\n",
    "import zipfile\n",
    "if not os.path.exists(\"ipeo_data\"):\n",
    "    with zipfile.ZipFile(\"ipeo_data.zip\", 'r') as zip_ref:\n",
    "        zip_ref.extractall()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f4fd97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6a721eb",
   "metadata": {},
   "source": [
    "## Set up the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf4a2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "\"\"\"CLASS rocks (1), scree (2), sparse rocks (3), water (4), glacier and permanent snow (5), forest(6), sparse forest(7),\n",
    "grasslands and others (8).\"\"\"\n",
    "\n",
    "class Alpine(Dataset):\n",
    "\n",
    "    # mapping between label class names and indices\n",
    "    LABEL_CLASSES = {\n",
    "      'rocks': \t\t  1,\n",
    "      'scree': \t\t\t    2,\n",
    "      'sparse_rocks': \t  3,\n",
    "      'water': \t\t\t\t      4,\n",
    "      'glacier_and_permanent_snow': \t\t\t    5,\n",
    "      'forest': \t\t\t    6,\n",
    "      'sparse_forest':   7,\n",
    "      'grasslands_and_others': \t\t\t\t    8,\n",
    "      \n",
    "    }\n",
    "\n",
    "    # image indices to use for different splits\n",
    "    SPLITS = {\n",
    "      'train': list(range(0, 60)),    # use first 60 images of each class for training...\n",
    "      'val':   list(range(61, 70)),   # ...images 61-70 for model validation...\n",
    "      'test':  list(range(71, 100))   # ...and the rest for testing\n",
    "    }\n",
    "\n",
    "    def __init__(self, transforms=None, split='train'):\n",
    "        self.transforms = transforms\n",
    "\n",
    "        # prepare data\n",
    "        self.data = []                                  # list of tuples of (image path, label class)\n",
    "        # get images with correct index according to dataset split\n",
    "        for imgIndex in self.SPLITS[split]:\n",
    "                imgName = os.path.join('ipeo_data/', .tif') \n",
    "                # example format: 'baseFolder/agricultural/agricultural07.tif'\n",
    "                self.data.append((\n",
    "                    imgName,\n",
    "                    self.LABEL_CLASSES[labelclass]          # get index for label class\n",
    "                ))\n",
    "\n",
    "\n",
    "    #TODO: please provide the remaining functions required for the torch.utils.data.Dataset class.\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "    def __getitem__(self, x):\n",
    "        imgName, label = self.data[x]\n",
    "\n",
    "        img = Image.open(imgName)\n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "        return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cebd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "# create 21 dummy predictions with 21 classes and random logits\n",
    "\"\"\"CLASSES : rocks (1), scree (2), sparse rocks (3), water (4), glacier and\n",
    "permanent snow (5), forest(6), sparse forest(7), grasslands and others (8).\"\"\"\n",
    "num_classes = 8\n",
    "batch_size = 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c43523",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import SGD\n",
    "\n",
    "learning_rate = 0.01\n",
    "# TODO instantiate the SGD optimizer\n",
    "optimizer = SGD(model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9587d218",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def training_step(batch, model, optimizer, device=\"cuda\"):\n",
    "    # TODO fill this function with the training step code\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    model.zero_grad()\n",
    "    \n",
    "    # TODO retrieve image and label from the batch\n",
    "    x, y = batch\n",
    "    \n",
    "    # TODO move model and code to GPU\n",
    "    model = model.to(device)\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    \n",
    "    # TODO forward pass\n",
    "    y_hat =  model(x)\n",
    "    \n",
    "    # TODO loss calculation\n",
    "    loss = criterion(y_hat,y)\n",
    "  \n",
    "    # TODO implement backprop and model update\n",
    "     # backpropoagation of gradients\n",
    "     # update model parameters\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # lets also calculate accuracy for fun\n",
    "    # FYI\n",
    "    # .cpu() moves the data back to cpu (if on GPU)\n",
    "    # .detach() removes gradients (we dont need them for accuracy)\n",
    "    # .numpy() converts the tensor to numpy for better handling later\n",
    "    predictions = y_hat.argmax(1).cpu().detach().numpy()\n",
    "    ground_truth = y.cpu().detach().numpy()\n",
    "    \n",
    "    # accuracy is the mean of correct (1) and incorrect (0) classifications\n",
    "    accuracy = (predictions == ground_truth).mean()\n",
    "  \n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b677cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a5c37f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181eb246",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f020886",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b68f0c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
